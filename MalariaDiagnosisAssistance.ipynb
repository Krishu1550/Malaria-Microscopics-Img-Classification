{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "concrete-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this cell if there is no GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "involved-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 124/124 [00:11<00:00, 10.92it/s]\n"
     ]
    }
   ],
   "source": [
    "##################### Parasite Segmentation: binary mask generation #################\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "sm.set_framework('tf.keras')\n",
    "\n",
    "model = sm.Unet('vgg19', encoder_weights=None)\n",
    "model.load_weights('E:/malaria_data/vgg19_color_ntl_dataset12_shuffle_nocrops_augmented.hdf5')\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
    "    loss=sm.losses.bce_jaccard_loss,\n",
    "    metrics=[sm.metrics.iou_score],\n",
    ")\n",
    "\n",
    "\n",
    "test_path = 'E:/malaria_data/dataset_2/test/img'\n",
    "predict_path = 'E:/malaria_data/dataset_2/test/predict'\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                                   samplewise_center=True,\n",
    "                                                                   samplewise_std_normalization=True)  # preprocessing_function=preprocess_input\n",
    "\n",
    "file_list = os.listdir(test_path)\n",
    "\n",
    "for file_name in tqdm(file_list):\n",
    "    \n",
    "    #original image reading\n",
    "    full_path = os.path.join(test_path, file_name)\n",
    "    img= cv2.imread(full_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_rgb = cv2.resize(img_rgb, (224, 224), interpolation = cv2.INTER_LINEAR) \n",
    "    x = np.expand_dims(img_rgb, axis=0)\n",
    "    \n",
    "    test_iterator = test_datagen.flow(x,batch_size=1)\n",
    "    x = test_iterator.next()\n",
    "    result = model.predict(x, verbose=0)\n",
    "    result = np.squeeze(result, axis=0)\n",
    "    result = np.where(result > 0.5, 255, 0)\n",
    "    #save predicted mask\n",
    "    full_path = os.path.join(predict_path, file_name)\n",
    "    cv2.imwrite(full_path, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "numerical-watershed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 124/124 [00:01<00:00, 85.05it/s]\n"
     ]
    }
   ],
   "source": [
    "############# Binary mask resize to original image size ###################\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def resize_function(input_directory, output_directory, new_w, new_h):\n",
    "    \n",
    "    original_file_list = os.listdir(input_directory)\n",
    "    \n",
    "    for img_file in tqdm(original_file_list):\n",
    "        \n",
    "        # read gt image in binary format\n",
    "        full_path = os.path.join(input_directory, img_file)\n",
    "        mask= cv2.imread(full_path, 0) # 0 for grayscale flag\n",
    "        (thresh, mask) = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        #resize\n",
    "        dsize = (new_w,new_h)\n",
    "        # resize image\n",
    "        mask = cv2.resize(mask, dsize)\n",
    "        (thresh, mask) = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # copy and paste original image\n",
    "        full_path = os.path.join(output_directory, img_file)\n",
    "        cv2.imwrite(full_path, mask)\n",
    "\n",
    "\n",
    "input_directory = \"E:/malaria_data/dataset_2/test/predict\"\n",
    "output_directory= \"E:/malaria_data/dataset_2/test/predict\"\n",
    "\n",
    "#dataset1\n",
    "#new_w = 2592\n",
    "#new_h = 1944\n",
    "\n",
    "#dataset2\n",
    "new_w = 1382\n",
    "new_h = 1030\n",
    "\n",
    "resize_function(input_directory, output_directory, new_w, new_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "subtle-arnold",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 124/124 [00:17<00:00,  7.17it/s]\n"
     ]
    }
   ],
   "source": [
    "##### Parasite contours delineation on original image, number of parasites is saved within the name of the image ########### \n",
    "import cv2 \n",
    "import numpy as np\n",
    "from cv2 import boxPoints\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def box_fun(gray_img,color_img):\n",
    "    (cnts, _) = cv2.findContours(gray_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "    gray_rgb = cv2.cvtColor(gray_img, cv2.COLOR_BGR2RGB)\n",
    "    #print(\"{}{}\".format('Detected parasites: ',len(c)))\n",
    "    for i in range(0,len(c)):\n",
    "        #use the 2 statement to trace boxes and replace c[i] by box\n",
    "        #rect = cv2.minAreaRect(c[i])\n",
    "        #box =  np.int0(boxPoints(rect))\n",
    "        cv2.drawContours(color_img, [c[i]], -1, (0, 0, 255), 3) \n",
    "        \n",
    "    return len(c), color_img \n",
    "\n",
    "\n",
    "# images and mask directories\n",
    "img_directory = 'E:/malaria_data/dataset_2/test/img'\n",
    "mask_directory = 'E:/malaria_data/dataset_2/test/predict'\n",
    "\n",
    "# contours output directory\n",
    "original_bb_directory = 'E:/malaria_data/dataset_2/test/contours'\n",
    "\n",
    "#gt_file_list = os.listdir(gt_directory)\n",
    "original_file_list = os.listdir(img_directory)\n",
    "\n",
    "for original_file_name in tqdm(original_file_list):\n",
    "    \n",
    "    #mask images reading and binary thresholding\n",
    "    mask_path = os.path.join(mask_directory, original_file_name)\n",
    "    mask_img= cv2.imread(mask_path, 0) # 0 for grayscale flag\n",
    "    (thresh, mask_img) = cv2.threshold(mask_img, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #original image reading\n",
    "    original_path = os.path.join(img_directory, original_file_name)\n",
    "    original_img= cv2.imread(original_path)\n",
    "    \n",
    "    #parasite counting for each image and contour tracing\n",
    "    parasite_count, original_img_bound = box_fun(mask_img,original_img)\n",
    "    \n",
    "    #save original img with boxes\n",
    "    new_name = original_file_name.split(\".png\", 1)\n",
    "    new_name = os.path.join(original_bb_directory, new_name[0]+\"_\"+str(parasite_count)+\"_parasites.png\")\n",
    "    cv2.imwrite(new_name, original_img_bound)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "conditional-popularity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 124/124 [00:09<00:00, 13.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of images without parasites: ['Trip 038 Day 1 01-12-05 Image 11 add_9.png', 'Trip 053 Day 2 19-11-05 Image 3_12.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " ###### Crop the largest parasite from each image and save it. Requires orginal image and associated binary mask ##########\n",
    "import cv2 \n",
    "import os\n",
    "import numpy as np\n",
    "from cv2 import boxPoints\n",
    "\n",
    "def savecrop(original_img, original_file_name, output_directory, x,y,w,h, window_h, window_w):\n",
    "    \n",
    "    extension=\".png\"\n",
    "    max_h= window_h # should be 224\n",
    "    max_w= window_w # should be 224\n",
    "    delta_h=max_h-h\n",
    "    delta_w=max_w-w\n",
    "    \n",
    "    #position center\n",
    "    a=y-(delta_h // 2)\n",
    "    b=y-(delta_h // 2)+max_h\n",
    "    e=x-(delta_w // 2)\n",
    "    f=x-(delta_w // 2)+max_w    \n",
    "    if a>=0 and b<=original_img.shape[0] and e>=0 and f<=original_img.shape[1]:\n",
    "        \n",
    "        new_img2=original_img[a:b,e:f]#img\n",
    "        #writes the new file in the Crops folder\n",
    "        new_name = original_file_name.split(extension, 1)[0]\n",
    "        full_path_file_name = os.path.join(output_directory, new_name +\".png\")\n",
    "        cv2.imwrite(full_path_file_name, new_img2) \n",
    "        return\n",
    "        \n",
    "    \n",
    "        \n",
    "    #position 4 middle left\n",
    "    a=y-(delta_h // 2)\n",
    "    b=a+max_h\n",
    "    e=x\n",
    "    f=e+max_w     \n",
    "    if a>=0 and b<=original_img.shape[0] and f<=original_img.shape[1]:\n",
    "        \n",
    "        new_img2=original_img[a:b,e:f]#img\n",
    "        #writes the new file in the Crops folder\n",
    "        new_name = original_file_name.split(extension, 1)[0]\n",
    "        full_path_file_name = os.path.join(output_directory, new_name +\".png\")\n",
    "        cv2.imwrite(full_path_file_name, new_img2)\n",
    "        return\n",
    "    \n",
    "    #position 6 middle right\n",
    "    a=y-(delta_h // 2)\n",
    "    b=a+max_h\n",
    "    e=x-delta_w\n",
    "    f=e+max_w    \n",
    "    if a>=0 and b<=original_img.shape[0] and e>=0 and f<=original_img.shape[1]:\n",
    "        \n",
    "        new_img2=original_img[a:b,e:f]#img\n",
    "        #writes the new file in the Crops folder\n",
    "        new_name = original_file_name.split(extension, 1)[0]\n",
    "        full_path_file_name = os.path.join(output_directory, new_name +\".png\")\n",
    "        cv2.imwrite(full_path_file_name, new_img2)\n",
    "        return\n",
    "\n",
    "    \n",
    "    #position 2 up center\n",
    "    a=y\n",
    "    b=y+max_h\n",
    "    e=x-(delta_w // 2)\n",
    "    f=x-(delta_w // 2)+max_w      \n",
    "    if e>=0 and b<=original_img.shape[0] and f<=original_img.shape[1]:\n",
    "        \n",
    "        new_img2=original_img[a:b,e:f]#img\n",
    "        #writes the new file in the Crops folder\n",
    "        new_name = original_file_name.split(extension, 1)[0]\n",
    "        full_path_file_name = os.path.join(output_directory, new_name +\".png\")\n",
    "        cv2.imwrite(full_path_file_name, new_img2)\n",
    "        return\n",
    "    \n",
    "    #position 1 up left\n",
    "    a=y\n",
    "    b=y+max_h\n",
    "    e=x\n",
    "    f=x+max_w        \n",
    "    if b<=original_img.shape[0] and f<=original_img.shape[1]:\n",
    "        \n",
    "        new_img2=original_img[a:b,e:f]#img\n",
    "        #writes the new file in the Crops folder\n",
    "        new_name = original_file_name.split(extension, 1)[0]\n",
    "        full_path_file_name = os.path.join(output_directory, new_name +\".png\")\n",
    "        cv2.imwrite(full_path_file_name, new_img2)\n",
    "        return\n",
    "    \n",
    "    #position 3 up right\n",
    "    a=y\n",
    "    b=y+max_h\n",
    "    e=x-delta_w\n",
    "    f=x-delta_w+max_w      \n",
    "    if b<=original_img.shape[0] and e>=0 and f<=original_img.shape[1]:\n",
    "        \n",
    "        new_img2=original_img[a:b,e:f]#img\n",
    "        #writes the new file in the Crops folder\n",
    "        new_name = original_file_name.split(extension, 1)[0]\n",
    "        full_path_file_name = os.path.join(output_directory, new_name +\".png\")\n",
    "        cv2.imwrite(full_path_file_name, new_img2)\n",
    "        return\n",
    "    \n",
    "    #position 8 down center\n",
    "    a=y-delta_h\n",
    "    b=a+max_h\n",
    "    e=x-(delta_w // 2)\n",
    "    f=e+max_w   \n",
    "    if a>=0 and b<=original_img.shape[0] and e>=0 and f<=original_img.shape[1]:\n",
    "        \n",
    "        new_img2=original_img[a:b,e:f]#img\n",
    "        #writes the new file in the Crops folder\n",
    "        new_name = original_file_name.split(extension, 1)[0]\n",
    "        full_path_file_name = os.path.join(output_directory, new_name +\".png\")\n",
    "        cv2.imwrite(full_path_file_name, new_img2)\n",
    "        return\n",
    "    \n",
    "    #position 7 down left\n",
    "    a=y-delta_h\n",
    "    b=a+max_h\n",
    "    e=x\n",
    "    f=e+max_w   \n",
    "    if a>=0 and b<=original_img.shape[0] and f<=original_img.shape[1]:\n",
    "        \n",
    "        new_img2=original_img[a:b,e:f]#img\n",
    "        #writes the new file in the Crops folder\n",
    "        new_name = original_file_name.split(extension, 1)[0]\n",
    "        full_path_file_name = os.path.join(output_directory, new_name +\".png\")\n",
    "        cv2.imwrite(full_path_file_name, new_img2)\n",
    "        return   \n",
    "            \n",
    "    #position 9 down right\n",
    "    a=y-delta_h\n",
    "    b=a+max_h\n",
    "    e=x-delta_w\n",
    "    f=e+max_w  \n",
    "    if a>=0 and b<=original_img.shape[0] and e>=0 and f<=original_img.shape[1]:\n",
    "        \n",
    "        new_img2=original_img[a:b,e:f]#img\n",
    "        #writes the new file in the Crops folder\n",
    "        new_name = original_file_name.split(extension, 1)[0]\n",
    "        full_path_file_name = os.path.join(output_directory, new_name +\".png\")\n",
    "        cv2.imwrite(full_path_file_name, new_img2)\n",
    "\n",
    "\n",
    "def crop_largest(gray_img,color_img, original_file_name, output_directory):\n",
    "    \n",
    "    (cnts, _) = cv2.findContours(gray_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    c = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "    \n",
    "    gray_rgb = cv2.cvtColor(gray_img, cv2.COLOR_BGR2RGB)\n",
    "    #print(\"{}{}\".format('Detected parasites: ',len(c)))\n",
    "    if (len(c)>0):\n",
    "        max_area = 0\n",
    "        index_max=-1\n",
    "        flag = 0\n",
    "        for i in range(0,len(c)):\n",
    "            x, y, w, h = cv2.boundingRect(c[i])\n",
    "            if((w*h > max_area)): #50176 and (w*h <= 50176)\n",
    "                index_max = i\n",
    "                max_area = w*h\n",
    "                flag = 1\n",
    "        \n",
    "        if(flag == 1):\n",
    "            x,y,w,h = cv2.boundingRect(c[index_max])\n",
    "            savecrop(color_img, original_file_name, output_directory, x,y,w,h, 224, 224)\n",
    "    else:\n",
    "        fn.append(original_file_name)\n",
    "        \n",
    "        \n",
    "\n",
    "mask_directory = \"E:/malaria_data/dataset_2/test/predict\"\n",
    "original_directory = \"E:/malaria_data/dataset_2/test/img\"\n",
    "output = \"E:/malaria_data/dataset_2/test/crops\"\n",
    "\n",
    "extension = \".png\"\n",
    "#gt_file_list = os.listdir(gt_directory)\n",
    "original_file_list = os.listdir(original_directory)\n",
    "fn=[]\n",
    "for original_file_name in tqdm(original_file_list):\n",
    "    \n",
    "    #mask images reading and binary thresholding\n",
    "    prefix_name = original_file_name.split(extension, 1)\n",
    "    mask_file_name = prefix_name[0] +extension\n",
    "    \n",
    "    mask_path = os.path.join(mask_directory, mask_file_name)\n",
    "    mask_img= cv2.imread(mask_path, 0) # 0 for grayscale flag\n",
    "    #gt_img=cv2.cvtColor(gt_img, cv2.COLOR_BGR2GRAY)\n",
    "    (thresh, mask_img) = cv2.threshold(mask_img, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #original image reading\n",
    "    original_path = os.path.join(original_directory, original_file_name)\n",
    "    original_img= cv2.imread(original_path)\n",
    "    \n",
    "    #crop largest parasite if it exists\n",
    "    crop_largest(mask_img,original_img,original_file_name, output)\n",
    "    \n",
    "print(\"List of images without parasites: %s\" % fn)    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "forbidden-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip 017 Day 1 19-10-05 Image 14 add_4.png [Falciparum]\n",
      "Trip 017 Day 1 19-10-05 Image 14 add_7.png [Falciparum]\n",
      "Trip 017 Day 1 19-10-05 Image 15 add_1.png [Falciparum]\n",
      "Trip 017 Day 1 19-10-05 Image 15 add_6.png [Falciparum]\n",
      "Trip 017 Day 1 19-10-05 Image 16 add_10.png [Falciparum]\n",
      "Trip 017 Day 1 19-10-05 Image 16 add_2.png [Falciparum]\n",
      "Trip 017 Day 1 19-10-05 Image 17 add_11.png [Falciparum]\n",
      "Trip 017 Day 1 19-10-05 Image 17 add_14.png [Falciparum]\n",
      "Trip 022 Day 1 08-11-05 Image 10 add_14.png [Falciparum]\n",
      "Trip 022 Day 1 08-11-05 Image 10 add_6.png [Falciparum]\n",
      "Trip 022 Day 1 08-11-05 Image 11 add_11.png [Falciparum]\n",
      "Trip 022 Day 1 08-11-05 Image 11 add_16.png [Falciparum]\n",
      "Trip 022 Day 1 08-11-05 Image 9 add_12.png [Falciparum]\n",
      "Trip 022 Day 1 08-11-05 Image 9 add_8.png [Falciparum]\n",
      "Trip 029 Day 1 22-11-05 Image 10 add_4.png [Falciparum]\n",
      "Trip 029 Day 1 22-11-05 Image 10 add_8.png [Falciparum]\n",
      "Trip 029 Day 1 22-11-05 Image 11 add_13.png [Falciparum]\n",
      "Trip 029 Day 1 22-11-05 Image 11 add_5.png [Falciparum]\n",
      "Trip 029 Day 1 22-11-05 Image 12 add_16.png [Falciparum]\n",
      "Trip 029 Day 1 22-11-05 Image 12 add_4.png [Falciparum]\n",
      "Trip 029 Day 1 22-11-05 Image 9 add_13.png [Falciparum]\n",
      "Trip 029 Day 1 22-11-05 Image 9 add_2.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 10 add_13.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 10 add_14.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 11 add_4.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 18 add_12.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 18 add_2.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 19 add_2.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 19 add_3.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 20 add_1.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 20 add_3.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 21 add_12.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 21 add_7.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 22 add_1.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 22 add_4.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 23 add_1.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 23 add_7.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 26 add_14.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 26 add_16.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 27 add_11.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 27 add_4.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 30 add_1.png [Falciparum]\n",
      "Trip 038 Day 1 01-12-05 Image 30 add_10.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 11 add_3.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 11 add_9.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 12 add_15.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 12 add_8.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 1_12.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 1_4.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 2_15.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 2_5.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 3_1.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 3_11.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 4_10.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 4_13.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 9 add_14.png [Falciparum]\n",
      "Trip 043 Day 2 24-10-05 Image 9 add_5.png [Falciparum]\n",
      "Trip 053 Day 2 19-11-05 Image 10 add_16.png [Vivax]\n",
      "Trip 053 Day 2 19-11-05 Image 10 add_8.png [Falciparum]\n",
      "Trip 053 Day 2 19-11-05 Image 1_14.png [Falciparum]\n",
      "Trip 053 Day 2 19-11-05 Image 1_7.png [Vivax]\n",
      "Trip 053 Day 2 19-11-05 Image 2_3.png [Falciparum]\n",
      "Trip 053 Day 2 19-11-05 Image 2_8.png [Falciparum]\n",
      "Trip 053 Day 2 19-11-05 Image 3_16.png [Falciparum]\n",
      "Trip 061 Day 2 19-11-05 Image 11 add_2.png [Falciparum]\n",
      "Trip 061 Day 2 19-11-05 Image 11 add_4.png [Falciparum]\n",
      "Trip 061 Day 2 19-11-05 Image 1_12.png [Falciparum]\n",
      "Trip 061 Day 2 19-11-05 Image 1_8.png [Falciparum]\n",
      "Trip 061 Day 2 19-11-05 Image 3_7.png [Falciparum]\n",
      "Trip 061 Day 2 19-11-05 Image 3_8.png [Falciparum]\n",
      "Trip 062 Day 1 02-11-05 Image 10 add_14.png [Falciparum]\n",
      "Trip 062 Day 1 02-11-05 Image 10 add_9.png [Falciparum]\n",
      "Trip 062 Day 1 02-11-05 Image 11 add_1.png [Falciparum]\n",
      "Trip 062 Day 1 02-11-05 Image 11 add_7.png [Falciparum]\n",
      "Trip 062 Day 1 02-11-05 Image 3_13.png [Vivax]\n",
      "Trip 062 Day 1 02-11-05 Image 3_7.png [Falciparum]\n",
      "Trip 062 Day 1 02-11-05 Image 9 add_3.png [Falciparum]\n",
      "Trip 062 Day 1 02-11-05 Image 9 add_7.png [Falciparum]\n",
      "Trip 064 Day 2 25-11-05 Image 5_11.png [Falciparum]\n",
      "Trip 064 Day 2 25-11-05 Image 5_6.png [Falciparum]\n",
      "Trip 064 Day 2 25-11-05 Image 7_1.png [Falciparum]\n",
      "Trip 064 Day 2 25-11-05 Image 7_3.png [Falciparum]\n",
      "Trip 065 Day 2 01-12-05 Image 1_10.png [Falciparum]\n",
      "Trip 065 Day 2 01-12-05 Image 1_5.png [Falciparum]\n",
      "Trip 065 Day 2 01-12-05 Image 7_1.png [Falciparum]\n",
      "Trip 065 Day 2 01-12-05 Image 7_6.png [Falciparum]\n",
      "Trip 067 Day 2 01-12-05 Image 1_14.png [Falciparum]\n",
      "Trip 067 Day 2 01-12-05 Image 1_9.png [Falciparum]\n",
      "Trip 067 Day 2 01-12-05 Image 3_14.png [Falciparum]\n",
      "Trip 067 Day 2 01-12-05 Image 3_16.png [Falciparum]\n",
      "Trip 073 Day 2 01-12-05 Image 1_16.png [Falciparum]\n",
      "Trip 073 Day 2 01-12-05 Image 1_5.png [Falciparum]\n",
      "Trip 083 Day 2 07-12-05 Image 2_15.png [Falciparum]\n",
      "Trip 083 Day 2 07-12-05 Image 2_2.png [Falciparum]\n",
      "Trip 083 Day 2 07-12-05 Image 3_4.png [Falciparum]\n",
      "Trip 083 Day 2 07-12-05 Image 3_8.png [Falciparum]\n",
      "Trip 802 Day 2 01-12-05 Image 5_3.png [Falciparum]\n",
      "Trip 802 Day 2 01-12-05 Image 5_4.png [Falciparum]\n",
      "Trip 802 Day 2 01-12-05 Image 6_16.png [Falciparum]\n",
      "Trip 802 Day 2 01-12-05 Image 6_5.png [Falciparum]\n",
      "Trip 802 Day 2 01-12-05 Image 9 add_1.png [Falciparum]\n",
      "Trip 802 Day 2 01-12-05 Image 9 add_15.png [Falciparum]\n",
      "Trip 804 Day 1 02-12-05 Image 19 add_3.png [Falciparum]\n",
      "Trip 804 Day 1 02-12-05 Image 19 add_8.png [Falciparum]\n",
      "Trip 804 Day 1 02-12-05 Image 1_13.png [Falciparum]\n",
      "Trip 804 Day 1 02-12-05 Image 1_8.png [Falciparum]\n",
      "Trip 804 Day 1 02-12-05 Image 3_3.png [Falciparum]\n",
      "Trip 804 Day 1 02-12-05 Image 3_5.png [Falciparum]\n",
      "Trip 807 Day 1 07-12-05 Image 1_16.png [Falciparum]\n",
      "Trip 807 Day 1 07-12-05 Image 1_3.png [Falciparum]\n",
      "Trip 807 Day 1 07-12-05 Image 2_1.png [Falciparum]\n",
      "Trip 807 Day 1 07-12-05 Image 2_3.png [Falciparum]\n",
      "Trip 807 Day 1 07-12-05 Image 6_11.png [Falciparum]\n",
      "Trip 807 Day 1 07-12-05 Image 6_7.png [Falciparum]\n",
      "Trip 807 Day 1 07-12-05 Image 8_12.png [Falciparum]\n",
      "Trip 807 Day 1 07-12-05 Image 8_7.png [Falciparum]\n",
      "Trip 808 Day 2 08-12-05 Image 1_12.png [Falciparum]\n",
      "Trip 808 Day 2 08-12-05 Image 1_7.png [Falciparum]\n",
      "Trip 808 Day 2 08-12-05 Image 3_10.png [Falciparum]\n",
      "Trip 808 Day 2 08-12-05 Image 3_15.png [Falciparum]\n",
      "Trip 808 Day 2 08-12-05 Image 5_2.png [Falciparum]\n",
      "Trip 808 Day 2 08-12-05 Image 5_9.png [Falciparum]\n"
     ]
    }
   ],
   "source": [
    "############ Load classifier and assign to each crop the predicted species ###############\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "model = load_model('E:/malaria_data/LightNet_classification_mixed.hdf5')\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "\n",
    "# The right species of all crops from this test is Falciparum\n",
    "test_path = 'E:/malaria_data/dataset_2/test/crops'\n",
    "\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                                   samplewise_center=True,\n",
    "                                                                   samplewise_std_normalization=True)  # preprocessing_function=preprocess_input\n",
    "\n",
    "file_list = os.listdir(test_path)\n",
    "plasmodium = ['Falciparum', 'Malariae', 'Ovale', 'Vivax']\n",
    "for file_name in file_list: #tqdm\n",
    "    \n",
    "    #original image reading\n",
    "    #print(file_name)\n",
    "    full_path = os.path.join(test_path, file_name)\n",
    "    img= cv2.imread(full_path)\n",
    "    img_rgb = cv2.resize(img, (224, 224), interpolation = cv2.INTER_LINEAR) \n",
    "    img_rgb = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB)\n",
    "    x = np.expand_dims(img_rgb, axis=0)\n",
    "    \n",
    "    test_iterator = test_datagen.flow(x,batch_size=1)\n",
    "    x = test_iterator.next()\n",
    "    result = model.predict(x, verbose=0)\n",
    "    \n",
    "    index = np.argmax(result,-1) # get class index of max value\n",
    "    print('%s [%s]' % (file_name,plasmodium[index[0]]) ) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-influence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.15",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
